# MediaPipe Objectron on CPU that produces 3D bounding boxes for objects.
type: "ObjectDetection3dCpuSubgraph"

# Input/Output streams and input side packets.
input_stream: "IMAGE:image"
input_stream: "DETECTION:detections"
# Path to TfLite model for 3D bounding box landmark prediction
input_side_packet: "MODEL_PATH:box_landmark_model_path"

# Bounding box landmarks topology definition.
# The numbers are indices in the box_landmarks list.
#
#       3 + + + + + + + + 7
#       +\                +\          UP
#       + \               + \
#       +  \              +  \        |
#       +   4 + + + + + + + + 8       | y
#       +   +             +   +       |
#       +   +             +   +       |
#       +   +     (0)     +   +       .------- x
#       +   +             +   +        \
#       1 + + + + + + + + 5   +         \
#        \  +              \  +          \ z
#         \ +               \ +           \
#          \+                \+
#           2 + + + + + + + + 6

# Collection of detected 3D objects, represented as a FrameAnnotation.
# output_stream: "FRAME_ANNOTATION:detected_objects"
# Collection of box landmarks. (NormalizedLandmarkList)
output_stream: "MULTI_LANDMARKS:multi_box_landmarks"
# Crop rectangles derived from bounding box landmarks.
# output_stream: "NORM_RECTS:multi_box_rects"

output_stream: "LIFTED_FRAME_ANNOTATION:detected_objects"


# Loads the file in the specified path into a blob.
node {
  calculator: "LocalFileContentsCalculator"
  input_side_packet: "FILE_PATH:0:box_landmark_model_path"
  output_side_packet: "CONTENTS:0:box_landmark_model_blob"
}

# Converts the input blob into a TF Lite model.
node {
  calculator: "TfLiteModelCalculator"
  input_side_packet: "MODEL_BLOB:box_landmark_model_blob"
  output_side_packet: "MODEL:box_landmark_model"
}


# Extracts image size from the input images.
node {
  calculator: "ImagePropertiesCalculator"
  input_stream: "IMAGE:image"
  output_stream: "SIZE:image_size"
}

# Converts results of box detection into rectangles (normalized by image size)
# that encloses the box.
node {
  calculator: "DetectionsToRectsCalculator"
  input_stream: "DETECTIONS:detections"
  input_stream: "IMAGE_SIZE:image_size"
  output_stream: "NORM_RECTS:box_rects_from_detections"
  options: {
    [mediapipe.DetectionsToRectsCalculatorOptions.ext] {
      output_zero_rect_for_empty_detections: false
    }
  }
}


# Outputs each element of box_rects at a fake timestamp for the rest of the
# graph to process. Clones image and image size packets for each
# single_box_rect at the fake timestamp. At the end of the loop, outputs the
# BATCH_END timestamp for downstream calculators to inform them that all
# elements in the vector have been processed.
node {
  calculator: "BeginLoopNormalizedRectCalculator"
  input_stream: "ITERABLE:box_rects_from_detections"
  input_stream: "CLONE:image"
  output_stream: "ITEM:single_box_rect"
  output_stream: "CLONE:landmarks_image"
  output_stream: "BATCH_END:box_rects_timestamp"
}

# Subgraph that localizes box landmarks.
node {
  calculator: "BoxLandmarkSubgraph"
  input_stream: "IMAGE:landmarks_image"
  input_side_packet: "MODEL:box_landmark_model"
  input_stream: "NORM_RECT:single_box_rect"
  output_stream: "NORM_LANDMARKS:single_box_landmarks"
}

# Collects a set of landmarks for each hand into a vector. Upon receiving the
# BATCH_END timestamp, outputs the vector of landmarks at the BATCH_END
# timestamp.
node {
  calculator: "EndLoopNormalizedLandmarkListVectorCalculator"
  input_stream: "ITEM:single_box_landmarks"
  input_stream: "BATCH_END:box_rects_timestamp"
  output_stream: "ITERABLE:multi_box_landmarks"
}

# Convert box landmarks to frame annotations.
node {
  calculator: "LandmarksToFrameAnnotationCalculator"
  input_stream: "MULTI_LANDMARKS:multi_box_landmarks"
  output_stream: "FRAME_ANNOTATION:box_annotations"
}

# Lift the 2D landmarks to 3D using EPnP algorithm.
node {
  name: "Lift2DFrameAnnotationTo3DCalculator"
  calculator: "Lift2DFrameAnnotationTo3DCalculator"
  input_stream: "FRAME_ANNOTATION:box_annotations"
  output_stream: "LIFTED_FRAME_ANNOTATION:detected_objects"
  options: {
    [mediapipe.Lift2DFrameAnnotationTo3DCalculatorOptions.ext] {
      normalized_focal_x: 1.0
      normalized_focal_y: 1.0
    }
  }
}
